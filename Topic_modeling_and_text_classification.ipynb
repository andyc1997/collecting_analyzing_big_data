{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf924ed1",
   "metadata": {},
   "source": [
    "### <font color='black'>Topic modeling and text classification</font>\n",
    "\n",
    "<font color='#404040'>In this notebook, we will perform topic modeling and text classification, relying on *gensim*. The main workflow goes as follows: First, we will create *unigram* and *bigram*. Then, we use unigram and bigram to perform topic modeling separately, and interpret the outcome. Finally, features from the topic models serve as an input for text classification to explain the ratings.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fad68a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\desktop\\kul - mstat\\collecting and analyzing bigdata\\proj\\.venv\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041db46",
   "metadata": {},
   "source": [
    "### <font color='black'>Import data</font>\n",
    "\n",
    "<font color='#404040'>First, we import data cleaned in the previous notebook with relative paths.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4565b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "dat = pd.read_csv('./data/training_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc999c9",
   "metadata": {},
   "source": [
    "### <font color='black'>Topic modeling with unigram</font>\n",
    "\n",
    "<font color='#404040'>First, we import data cleaned in the previous notebook with relative paths.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c380f1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unigram tokens for gensim models\n",
    "def tokenize_comments(comments):\n",
    "    comments_tokenized = []\n",
    "\n",
    "    for comment in comments:\n",
    "        # If the comment is not missing\n",
    "        if pd.isnull(comment) == False:\n",
    "            sentence = []\n",
    "            \n",
    "            # Loop through each word in tokenized comment, add to the sentence list\n",
    "            for word in word_tokenize(comment):\n",
    "                sentence.append(word) \n",
    "            \n",
    "            # Update\n",
    "            comments_tokenized.append(sentence)\n",
    "\n",
    "    return comments_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90451bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(dat_uni):\n",
    "    # Use cleaned comments to create tokens\n",
    "    comments_tonkenized = tokenize_comments(dat_uni['reviews_lem'])\n",
    "\n",
    "    # Create dictionary and corpus - (token_id, token_count)\n",
    "    dictionary = corpora.Dictionary(comments_tonkenized)\n",
    "    dictionary.filter_extremes(no_above = 0.8) # Avoid common token\n",
    "    corpus = [dictionary.doc2bow(token) for token in comments_tonkenized]\n",
    "    \n",
    "    # Store corpus, dictionary and tokenized comments in a dict() object\n",
    "    # Because LdaModel and CoherenceModel takes them as arguments\n",
    "    return {'corpus': corpus, 'dictionary': dictionary, 'comments_tokenized': comments_tonkenized}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e774a91a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create unigram / tokenization for each university\n",
    "unigram_oxford = get_corpus(dat[dat['University'] == 'oxford'])\n",
    "unigram_edinburgh = get_corpus(dat[dat['University'] == 'edinburgh'])\n",
    "unigram_warwick = get_corpus(dat[dat['University'] == 'warwick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f68ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA models, and assess the performance using coherence scores\n",
    "# Seed is needed because the LDA model changes the results when we rerun the script\n",
    "SEED = 20210526\n",
    "unigram_results = []\n",
    "\n",
    "# Loop through each unversity\n",
    "for unigram in [unigram_oxford, unigram_edinburgh, unigram_warwick]:\n",
    "    # Assume there are at most 15 topics, a reasonable upper bound for small-to-medium dataset\n",
    "    coherence_scores = []\n",
    "    \n",
    "    for n_topics in np.arange(1, 15):\n",
    "        # Instantiate a lda model\n",
    "        ldamodel = gensim.models.ldamodel.LdaModel(unigram['corpus'], num_topics = n_topics, id2word = unigram['dictionary'], \n",
    "                                                   iterations = 1000, random_state = SEED)\n",
    "        \n",
    "        # Instantiate a coherence model and calculate the coherence scores\n",
    "        ldamodel_coherence = CoherenceModel(model = ldamodel, texts = unigram['comments_tokenized'], dictionary = unigram['dictionary'], \n",
    "                                            coherence ='c_v')\n",
    "        \n",
    "        # Update\n",
    "        coherence_scores.append(ldamodel_coherence.get_coherence())\n",
    "    \n",
    "    # Update\n",
    "    unigram_results.append(coherence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f62e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86be6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
